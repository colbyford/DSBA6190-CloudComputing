{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1649368505577
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to work with dsba6190ml\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment, Run, Model\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to work with', ws.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "## Get experiment and run of interest\n",
    "experiment = Experiment(workspace=ws, name='instructor_automl_diabetes')\n",
    "run = Run(experiment, run_id = \"AutoML_2f266fb1-d22a-41f4-9ec2-58ee52e1ae69_46\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log_loss': 0.11075534524009302,\n",
       " 'precision_score_weighted': 0.9564538972783089,\n",
       " 'precision_score_micro': 0.9564570783554568,\n",
       " 'f1_score_micro': 0.9564570783554568,\n",
       " 'matthews_correlation': 0.9022974726242879,\n",
       " 'recall_score_macro': 0.9507251765177537,\n",
       " 'f1_score_weighted': 0.9564376425031265,\n",
       " 'precision_score_binary': nan,\n",
       " 'average_precision_score_micro': 0.9931689420359874,\n",
       " 'balanced_accuracy': 0.9507251765177537,\n",
       " 'recall_score_binary': nan,\n",
       " 'AUC_macro': 0.9921501711655808,\n",
       " 'f1_score_macro': 0.9511289284461748,\n",
       " 'accuracy': 0.9564570783554568,\n",
       " 'AUC_weighted': 0.9921501711655808,\n",
       " 'AUC_binary': nan,\n",
       " 'AUC_micro': 0.9929895504237377,\n",
       " 'average_precision_score_macro': 0.9905396529134274,\n",
       " 'weighted_accuracy': 0.9610813822458074,\n",
       " 'precision_score_macro': 0.9515761766895965,\n",
       " 'recall_score_weighted': 0.9564570783554568,\n",
       " 'average_precision_score_weighted': 0.9923721633793233,\n",
       " 'norm_macro_recall': 0.9014503530355075,\n",
       " 'recall_score_micro': 0.9564570783554568,\n",
       " 'average_precision_score_binary': nan,\n",
       " 'f1_score_binary': nan,\n",
       " 'accuracy_table': 'aml://artifactId/ExperimentRun/dcid.AutoML_2f266fb1-d22a-41f4-9ec2-58ee52e1ae69_46/accuracy_table',\n",
       " 'confusion_matrix': 'aml://artifactId/ExperimentRun/dcid.AutoML_2f266fb1-d22a-41f4-9ec2-58ee52e1ae69_46/confusion_matrix'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model...\n",
      "Model registered.\n"
     ]
    }
   ],
   "source": [
    "## Register the model\n",
    "print('Registering model...')\n",
    "run.register_model(model_path='outputs/model.pkl', model_name='inst_automl_diabetes_model',\n",
    "                   tags={'Training context':'Inline Training'},\n",
    "                   properties={'AUC Weighed': run.get_metrics()['AUC_weighted'],\n",
    "                               'Weighted Accuracy': run.get_metrics()['weighted_accuracy']})\n",
    "\n",
    "## Get the registered model\n",
    "model = ws.models['inst_automl_diabetes_model']\n",
    "\n",
    "print('Model registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a model as a web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./diabetes_service folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "## Create a folder for the deployment files\n",
    "deployment_folder = './diabetes_service'\n",
    "os.makedirs(deployment_folder, exist_ok=True)\n",
    "print(deployment_folder, 'folder created.')\n",
    "\n",
    "## Set path for scoring script\n",
    "script_file = 'score_diabetes.py'\n",
    "script_path = os.path.join(deployment_folder,script_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need an entry script that the service will use to score new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./diabetes_service/score_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_path\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = json.loads(raw_data)['data']\n",
    "    np_data = np.array(data)\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(np_data)\n",
    "    \n",
    "    # print the data and predictions (so they'll be logged!)\n",
    "    log_text = 'Data:' + str(data) + ' - Predictions:' + str(predictions)\n",
    "    print(log_text)\n",
    "    \n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['not-diabetic', 'diabetic']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can deploy the service (in this case, as an Azure Container Instance (ACI).\n",
    "\n",
    "> **Note**: This can take a few minutes - wait until the state is shown as **Healthy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "## Configure the scoring environment\n",
    "\n",
    "curated_env_name = 'AzureML-pytorch-1.7-ubuntu18.04-py37-cuda11-gpu'\n",
    "pytorch_env = Environment.get(workspace=ws, name=curated_env_name)\n",
    "\n",
    "aci_service_env = Environment(name='inst_automl_aci_service-env')\n",
    "python_packages = ['scikit-learn', 'azureml-defaults', 'azureml-sdk[automl]', 'azure-ml-api-sdk']\n",
    "for package in python_packages:\n",
    "    aci_service_env.python.conda_dependencies.add_pip_package(package)\n",
    "inference_config = InferenceConfig(source_directory=deployment_folder,\n",
    "                                   entry_script=script_file,\n",
    "                                   environment=aci_service_env)\n",
    "\n",
    "## Configure the web service container\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26927/2140985576.py:5: FutureWarning: azureml.core.model:\n",
      "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
      "please refer to respective documentations \n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
      "For more information on migration, see https://aka.ms/acimoemigration. \n",
      "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
      "  aci_service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2023-03-18 16:31:52+00:00 Creating Container Registry if not exists.\n",
      "2023-03-18 16:31:52+00:00 Registering the environment.\n",
      "2023-03-18 16:31:53+00:00 Building image."
     ]
    }
   ],
   "source": [
    "## Deploy the model as a service\n",
    "\n",
    "print('Deploying model...')\n",
    "service_name = \"inst-automl-diabetes-service1\"\n",
    "aci_service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
    "aci_service.wait_for_deployment(show_output = True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the web service\n",
    "\n",
    "With the service deployed, now you can consume it from a client application.\n",
    "\n",
    "First, determine the URL to which these applications must submit their requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "endpoint = aci_service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know the endpoint URI, an application can simply make an HTTP request, sending the patient data in JSON (or binary) format, and receive back the predicted class(es).\n",
    "\n",
    "> **Tip**: If an error occurs because the service endpoint isn't ready. Wait a few seconds and try again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Create new data for inferencing\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "# Get the predictions\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "print(predictions.status_code)\n",
    "if predictions.status_code == 200:\n",
    "    predicted_classes = json.loads(predictions.json())\n",
    "    for i in range(len(x_new)):\n",
    "        print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
